{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> 11c3bc31669ce8191c356af2827ce0275881480e
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from innvestigate.utils.keras import checks\n",
    "from innvestigate.utils.keras import checks as kchecks\n",
    "from innvestigate.utils.keras import backend as kb\n",
    "from innvestigate.utils.keras import applications as kapp\n",
    "from innvestigate import create_analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_regression_feature_importance(model_file, feature_names):\n",
    "    \"\"\"\n",
    "    Extracts feature importance from a linear regression model stored in a .sav file.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_file (str): File path to the .sav file containing the linear regression model.\n",
    "    - feature_names (list): List of feature names.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing the feature names and their corresponding importance.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_file)\n",
    "\n",
    "    coefficients = model.coef_\n",
    "\n",
    "    absolute_coefficients = np.abs(coefficients)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    normalized_coefficients = scaler.fit_transform(absolute_coefficients.reshape(-1, 1)).flatten()\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': normalized_coefficients})\n",
    "\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return feature_importance_df\n",
    "\n",
    "\n",
    "def get_svm_feature_importance(model_file, feature_names, X_train=[]):\n",
    "    \"\"\"\n",
    "    Extracts feature importance from an SVM model stored in a .sav file.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_file (str): File path to the .sav file containing the SVM model.\n",
    "    - feature_names (list): List of feature names.\n",
    "    - X_train (DataFrame or array-like): Training data used to fit the SVM model.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing the feature names and their corresponding importance.\n",
    "    \"\"\"\n",
    "    model = joblib.load(model_file)\n",
    "\n",
    "    if model.kernel == 'linear':\n",
    "        coefficients = model.coef_.flatten()\n",
    "        importance = np.abs(coefficients)\n",
    "    else:\n",
    "        print(\"Feature importance for non-linear SVMs is not implemented yet. (Hard and Need to be done during the training processes)\")\n",
    "        return \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    normalized_importance = scaler.fit_transform(importance.reshape(-1, 1)).flatten()\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': normalized_importance})\n",
    "\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return feature_importance_df\n",
    "\n",
    "def get_lstm_feature_importance(model, X):\n",
    "    \"\"\"\n",
    "    Extracts feature importance from an LSTM model.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The LSTM model.\n",
    "    - X (array-like): Input data.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing the feature names and their corresponding importance.\n",
    "    \"\"\"\n",
    "    # Create an analyzer\n",
    "    analyzer = create_analyzer(\"lrp.epsilon\", model)\n",
    "\n",
    "    # Analyze the input data\n",
    "    relevance = analyzer.analyze(X)\n",
    "\n",
    "    # Summarize the relevance scores across time steps\n",
    "    feature_importance = np.sum(relevance, axis=0)\n",
    "\n",
    "    # Normalize the importance scores\n",
    "    normalized_importance = feature_importance / np.max(feature_importance)\n",
    "\n",
    "    # Assuming each feature corresponds to a time step\n",
    "    feature_names = [f\"Time Step {i+1}\" for i in range(X.shape[1])]\n",
    "\n",
    "    # Create a DataFrame to store feature names and their corresponding importance\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': normalized_importance})\n",
    "\n",
    "    # Rank features based on importance\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return feature_importance_df\n",
    "\n",
    "# Example usage:\n",
    "# Load your LSTM model and input data\n",
    "lstm_model = ...  # Your LSTM model\n",
    "X_data = ...  # Your input data\n",
    "feature_importance = get_lstm_feature_importance(lstm_model, X_data)\n",
    "print(\"Ranked Feature Importance:\")\n",
    "print(feature_importance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_regression_feature_importance(model_file, feature_names):\n",
    "    \"\"\"\n",
    "    Extracts feature importance from a linear regression model stored in a .sav file.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_file (str): File path to the .sav file containing the linear regression model.\n",
    "    - feature_names (list): List of feature names.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing the feature names and their corresponding importance.\n",
    "    \"\"\"\n",
    "\n",
    "    model = joblib.load(model_file)\n",
    "\n",
    "    coefficients = model.coef_\n",
    "\n",
    "    absolute_coefficients = np.abs(coefficients)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    normalized_coefficients = scaler.fit_transform(absolute_coefficients.reshape(-1, 1)).flatten()\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': normalized_coefficients})\n",
    "\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return feature_importance_df\n",
    "\n",
    "\n",
    "def get_svm_feature_importance(model_file, feature_names, X_train=[]):\n",
    "    \"\"\"\n",
    "    Extracts feature importance from an SVM model stored in a .sav file.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_file (str): File path to the .sav file containing the SVM model.\n",
    "    - feature_names (list): List of feature names.\n",
    "    - X_train (DataFrame or array-like): Training data used to fit the SVM model.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: DataFrame containing the feature names and their corresponding importance.\n",
    "    \"\"\"\n",
    "    model = joblib.load(model_file)\n",
    "\n",
    "    if model.kernel == 'linear':\n",
    "        coefficients = model.coef_.flatten()\n",
    "        importance = np.abs(coefficients)\n",
    "    else:\n",
    "        print(\"Feature importance for non-linear SVMs is not implemented yet. (Hard and Need to be done during the training processes)\")\n",
    "        return \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    normalized_importance = scaler.fit_transform(importance.reshape(-1, 1)).flatten()\n",
    "\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': normalized_importance})\n",
    "\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    return feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Importance\n",
      "3   Close    1.997547\n",
      "2     Low   -0.435193\n",
      "1    High   -0.457862\n",
      "0    Open   -0.531928\n",
      "4  Volume   -0.572564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivobook\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.4.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
>>>>>>> 11c3bc31669ce8191c356af2827ce0275881480e
    "path = \"models/LinearRegression.sav\"\n",
    "feature_names = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "feature_importance_df = get_linear_regression_feature_importance(path, feature_names)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Importance\n",
      "3   Close    1.182225\n",
      "1    High    0.615189\n",
      "0    Open    0.202764\n",
      "2     Low   -0.231189\n",
      "4  Volume   -1.768990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivobook\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.4.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
>>>>>>> 11c3bc31669ce8191c356af2827ce0275881480e
   "source": [
    "path = \"models/LinearRegression_log.sav\"\n",
    "feature_names = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "feature_importance_df = get_linear_regression_feature_importance(path, feature_names)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = 'models/SVM.sav'\n",
    "feature_names =  [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "X_train = [] \n",
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for non-linear SVMs is not implemented yet. (Hard and Need to be done during the training processes)\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivobook\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVR from version 1.4.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_file_path = 'models/SVM.sav'\n",
    "feature_names =  [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "X_train = []  # training data (How to get this easily without running the model file)\n",
>>>>>>> 11c3bc31669ce8191c356af2827ce0275881480e
    "feature_importance = get_svm_feature_importance(model_file_path, feature_names, X_train)\n",
    "print(feature_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
